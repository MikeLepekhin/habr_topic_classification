{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "parse_habr.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "sixth-argument"
      },
      "source": [
        "import numpy as np\n",
        "from multiprocessing import Pool"
      ],
      "id": "sixth-argument",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "diagnostic-hybrid"
      },
      "source": [
        "#!mkdir clean_files\n",
        "#!mkdir html_files"
      ],
      "id": "diagnostic-hybrid",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JgNYlvr_BVKv"
      },
      "source": [
        "import pickle\r\n",
        "from bs4 import BeautifulSoup\r\n",
        "\r\n",
        "\r\n",
        "def make_marks(content):\r\n",
        "    # Удаляем вставленные в текст блоки кода, оставляем пометки\r\n",
        "    for codeBlock in content.find_all('code'):\r\n",
        "        codeBlock.string = '<deleted block of code mark>'\r\n",
        "    # Вместо картинок тоже оставляем пометки, т.к. без них текст часто теряет смысл\r\n",
        "    for image in content.find_all('img'):\r\n",
        "        image.string = '<deleted image mark>'\r\n",
        "    for heading in content.find_all('h3'):\r\n",
        "        heading.string = '<header start mark>' + heading.string + '<header end mark>'\r\n",
        "    for url in content.find_all('a'):\r\n",
        "        try:\r\n",
        "            url.string = '<in text url start mark: ' + url['href'] + '>' \r\n",
        "            + url.string + '<in text url end mark>'\r\n",
        "        except:\r\n",
        "            pass\r\n",
        "    return content \r\n",
        "\r\n",
        "\r\n",
        "def parse(page):\r\n",
        "    soup = BeautifulSoup(page, 'html5lib') # instead of html.parser\r\n",
        "    doc = {}\r\n",
        "    if not soup.find(\"span\", {\"class\": \"post__title-text\"}):\r\n",
        "        # такое бывает, если статья не существовала или удалена\r\n",
        "        doc['status'] = 'title_not_found'\r\n",
        "    else:\r\n",
        "        content = make_marks(soup.find(\"div\", {\"class\": \"post__text\"}))\r\n",
        "\r\n",
        "        doc['status'] = 'ok'\r\n",
        "        doc['title'] = soup.find(\"span\", {\"class\": \"post__title-text\"}).text\r\n",
        "        doc['text'] = content.text\r\n",
        "        doc['time'] = soup.find(\"span\", {\"class\": \"post__time\"}).text\r\n",
        "        doc['hubs'] = soup.find(\"ul\", {\"class\": \"post__hubs\"}).text\r\n",
        "        doc['likes'] = soup.find(\"span\", {\"class\": \"voting-wjt__counter\"}).text\r\n",
        "    \r\n",
        "    return doc"
      ],
      "id": "JgNYlvr_BVKv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "decreased-ground"
      },
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def download_document(pid):\n",
        "    \"\"\" Download and process a Habr document and its comments \"\"\"\n",
        "    # выгрузка документа\n",
        "    r = requests.get('https://habrahabr.ru/post/' +str(pid) + '/')\n",
        "    # парсинг документа\n",
        "    soup = BeautifulSoup(r.text, 'html5lib') # instead of html.parser\n",
        "\n",
        "    doc = parse(soup)\n",
        "    doc['id'] = pid\n",
        "    \n",
        "    if 'hubs' in doc:    \n",
        "        # сохранение результата в отдельный файл\n",
        "        clean_filename = r'clean_files/' + str(pid) + '.pkl'\n",
        "        with open(clean_filename, 'wb') as f:\n",
        "            pickle.dump(doc, f)\n",
        "        \n",
        "        html_filename = r'html_files/' + str(pid) + '.html'\n",
        "        with open(html_filename, 'w') as html_out:\n",
        "            html_out.write(r.text)"
      ],
      "id": "decreased-ground",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "common-andrews"
      },
      "source": [
        "with Pool(10) as p:\n",
        "    docs = p.imap_unordered(download_document, np.arange(150000, 545000))"
      ],
      "id": "common-andrews",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "molecular-clause"
      },
      "source": [
        ""
      ],
      "id": "molecular-clause",
      "execution_count": null,
      "outputs": []
    }
  ]
}