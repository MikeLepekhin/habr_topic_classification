{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "reliable-annotation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "narrative-influence",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!mkdir clean_files\n",
    "#!mkdir html_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "molecular-miniature",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def download_document(pid):\n",
    "    \"\"\" Download and process a Habr document and its comments \"\"\"\n",
    "    # выгрузка документа\n",
    "    r = requests.get('https://habrahabr.ru/post/' +str(pid) + '/')\n",
    "    # парсинг документа\n",
    "    soup = BeautifulSoup(r.text, 'html5lib') # instead of html.parser\n",
    "    doc = {}\n",
    "    doc['id'] = pid\n",
    "    if not soup.find(\"span\", {\"class\": \"post__title-text\"}):\n",
    "        # такое бывает, если статья не существовала или удалена\n",
    "        doc['status'] = 'title_not_found'\n",
    "    else:\n",
    "        doc['status'] = 'ok'\n",
    "        doc['title'] = soup.find(\"span\", {\"class\": \"post__title-text\"}).text\n",
    "        doc['text'] = soup.find(\"div\", {\"class\": \"post__text\"}).text\n",
    "        doc['time'] = soup.find(\"span\", {\"class\": \"post__time\"}).text\n",
    "        doc['hubs'] = soup.find(\"ul\", {\"class\": \"post__hubs\"}).text\n",
    "        doc['likes'] = soup.find(\"span\", {\"class\": \"voting-wjt__counter\"}).text\n",
    "    \n",
    "    if 'hubs' in doc:    \n",
    "        # сохранение результата в отдельный файл\n",
    "        clean_filename = r'clean_files/' + str(pid) + '.pkl'\n",
    "        with open(clean_filename, 'wb') as f:\n",
    "            pickle.dump(doc, f)\n",
    "        \n",
    "        html_filename = r'html_files/' + str(pid) + '.pkl'\n",
    "        with open(html_filename, 'w') as html_out:\n",
    "            html_out.write(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charming-respect",
   "metadata": {},
   "outputs": [],
   "source": [
    "with Pool(10) as p:\n",
    "    docs = p.map(download_document, np.arange(313000, 500000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "desperate-assignment",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
